# News-Bias-Assessment
#### [News-Bias-Assessment](https://github.com/Data-Science-for-Linguists-2025/News-Bias-Assessment)

Sara's comments:
- Your progress report and notebook are both pretty clear, and this is a really interesting and necessary project!
- AllSides seems to be an interesting website! That being said, putting AP in the same category as Democracy Now seems a bit ridiculous to me, so definitely be a little skeptical of your sources.
- Unfortunately there's no samples of the data, but I would love to see some!
- One thing I've learned: The work on intensifiers seems really cool. It also seems similar to some of the stance work going on in sociolinguistics!
  
Ashley -
I think this is a very cool project idea! Your plan is very thorough so far which is nice, I feel like I have a really good
grasp of what to expect from your project already. 

Have you considered including the use of passive voice in headlines or articles? I feel like I've seen
examples before of the same news story from two different sites with two different framings by active vs passive voice.
(Might not be suited for this iteration of the project, but something that came to my mind)

I appreciate that you spell out the exact sourcing of your data pretty thoroughly. It seems like you put in the work to find
biased news sources while avoiding being biased in your sourcing yourself. Good to see!

Your progree report is nicely organized. I'm taking notes to make my own look just a little bit nicer too :)

Qidu's comments
- I like your idea. It is very interesting and I think it is fun project on analyzing bias in news articles. 
- Your documentation of the your project progress is very detailed and easy to follow.
- It may help readability when contents are added to the beginning of the ipynb files. 
You may want to supress some output displays in the ipynb files since they may be hard to read and unnecessary. 
- One thing I learned the possible corpus-pragmatic/intensification approach to analyzing objectivity/similarities. 

Lillian Carlson
- Your project has a lot of really insightful linguistic analysis with links to a lot of great papers about said linguistic phenomenae. It's a very interesting angle in terms of analyzing bias (something I have little experience with) and I am looking forward to seeing the results of the project!
- I think it would be great if the README was updated to at least list the contents, goal of the projects, ect (I just know I personally always go to the README first to get a lay of the land). One other thing would be to flash less of the articles so they didn't take up the whole screen (specifically the vox article and potential copyright issues).
- As I said before, I learned about looking at bias through a linguistic point of vewi and how that can be identified in texts, with a lot of great papers linked for further reading!

Comments from Jenna:
- There's so much stuff involved in your pipeline! The different details, etc. are astounding.
- I think it would be cool if you collected data/sorted by authors of the articles so that you could eliminate idiolect-caused patterns!
- I wish I had seen this sooner! I had a really difficult time working with bs4 parsing, and your work here definitely made me understand it a lot better

Comments from Jana:
- Your project plan is a very complete roadmap, and you always keep in mind and remind the reader that you might make some changes due to time and resource constraints.
- On the data pipeline, I would consider chopping off the output data. It makes it a bit harder to follow your notebook and see the relevant and probably very time-consuming steps you took in the processing stage.
- I learned that you can measure bias through Factive verbs, Subjective intensifiers, and One-sided terms, which I had no idea about. I also learned that you could scrape newspapers, which I hadn't thought of as a possibility and, I think, makes for an amazing resource. I'm looking forward to seeing what comes out of this bias-assessment!